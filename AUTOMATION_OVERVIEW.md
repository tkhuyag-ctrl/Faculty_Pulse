# Faculty Pulse - Automated Data Collection System

Complete automation system for keeping your Faculty Pulse database up-to-date.

---

## ğŸ“‹ Overview

This system automatically maintains your faculty and publication database with zero manual intervention.

### What It Does

1. **Faculty Synchronization**
   - Monitors Haverford faculty directory
   - Detects new faculty additions
   - Identifies faculty departures
   - Tracks department changes

2. **Publication Updates**
   - Fetches latest publications from OpenAlex
   - Adds only new publications (no duplicates)
   - Enriches with metadata (DOI, PDF links, citations)
   - Supports all faculty with OpenAlex IDs

3. **Automatic Scheduling**
   - Runs every 2 weeks automatically
   - No manual intervention required
   - Creates detailed logs and reports

---

## ğŸ—‚ï¸ File Structure

```
Faculty_Pulse/
â”œâ”€â”€ sync_faculty_data.py           # Step 1: Faculty sync from website
â”œâ”€â”€ auto_update_publications.py    # Step 2: Fetch new publications
â”œâ”€â”€ automated_data_updater.py      # Main: Runs both steps
â”œâ”€â”€ schedule_updates.py            # Setup: Creates scheduled task
â”œâ”€â”€ QUICKSTART_AUTOMATION.md       # Quick 5-minute setup guide
â”œâ”€â”€ AUTOMATED_UPDATES_README.md    # Detailed documentation
â””â”€â”€ AUTOMATION_OVERVIEW.md         # This file
```

---

## ğŸš€ Quick Start

**1. Test it works:**
```bash
python automated_data_updater.py
```

**2. Set up automatic scheduling:**
```bash
python schedule_updates.py
```
Choose option 1, done!

**Full guide:** See [QUICKSTART_AUTOMATION.md](QUICKSTART_AUTOMATION.md)

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Windows Task Scheduler                     â”‚
â”‚              (Triggers every 2 weeks)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           automated_data_updater.py (Main)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Faculty Sync    â”‚  â”‚  Publication Update  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                  â”‚  â”‚                      â”‚
â”‚ 1. Fetch website â”‚  â”‚ 1. Load faculty list â”‚
â”‚ 2. Compare local â”‚  â”‚ 2. Check OpenAlex    â”‚
â”‚ 3. Identify Î”    â”‚  â”‚ 3. Filter new pubs   â”‚
â”‚ 4. Update JSON   â”‚  â”‚ 4. Add to ChromaDB   â”‚
â”‚ 5. Create backup â”‚  â”‚ 5. Generate report   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Logs & Stats  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Features

### Faculty Sync
- âœ… Automatic faculty list updates
- âœ… Detects additions, removals, changes
- âœ… Creates backups before modifications
- âœ… Smart name matching (handles variations)
- âœ… Department tracking

### Publication Updates
- âœ… Fetches from OpenAlex API
- âœ… Duplicate detection (never adds twice)
- âœ… Incremental updates (only recent pubs)
- âœ… Full metadata (DOI, PDF, citations, venue)
- âœ… Error handling (continues if one fails)
- âœ… Batch processing (all faculty)

### Scheduling
- âœ… Windows Task Scheduler integration
- âœ… Runs every 2 weeks (configurable)
- âœ… Works even when not logged in
- âœ… Auto-retry if run was missed
- âœ… Easy enable/disable

### Logging & Monitoring
- âœ… Detailed timestamped logs
- âœ… Statistics and summary reports
- âœ… JSON results for automation
- âœ… Error tracking

---

## ğŸ“… Default Schedule

**Frequency:** Every 2 weeks
**Day:** Sunday
**Time:** 2:00 AM
**Duration:** ~15-20 minutes

### Why These Defaults?

- **2 weeks:** Good balance between freshness and API courtesy
- **Sunday 2 AM:** Low system usage time, less likely to interfere
- **60 days lookback:** Ensures no publications missed between runs

All configurable - see documentation for customization.

---

## ğŸ“ˆ Expected Results

### Per Run Statistics

**Faculty Sync (typical):**
- New faculty: 0-2
- Removed faculty: 0-1
- Updated faculty: 0-3
- Duration: 10-30 seconds

**Publication Updates (typical):**
- Faculty processed: ~50
- New publications: 5-20
- Duplicates skipped: 0-5
- Duration: 5-15 minutes

**Note:** Numbers vary based on actual faculty activity!

---

## ğŸ”§ Configuration

### Change Update Frequency

**Edit in Task Scheduler:**
1. `taskschd.msc` â†’ Find task
2. Triggers â†’ Edit â†’ Change recurrence

**Options:**
- Weekly: 1 week
- Bi-weekly: 2 weeks (default)
- Monthly: 4 weeks

### Change Lookback Period

**Edit `automated_data_updater.py`:**
```python
# Line ~50, change days_back parameter:
results = updater.run_full_update(days_back=60)  # Default

# Options:
days_back=30   # Weekly updates
days_back=60   # Bi-weekly updates (default)
days_back=90   # Monthly updates
```

### Customize Faculty Parsing

**Edit `sync_faculty_data.py`:**

The `fetch_current_faculty_from_website()` method needs website-specific selectors.

**You must update this based on actual Haverford website HTML!**

Example:
```python
# Find the right CSS selectors by inspecting the website
faculty_cards = soup.find_all('div', class_='faculty-card')
for card in faculty_cards:
    name = card.find('h3', class_='name').text
    dept = card.find('span', class_='dept').text
```

---

## ğŸ“‹ Workflow Example

### First Run (Initial Setup)

```
11:00 AM - User runs: python automated_data_updater.py
11:00 AM - Faculty sync starts
11:00 AM   - Loads local: 47 faculty
11:00 AM   - Fetches website: 48 faculty
11:00 AM   - New: 1 (Dr. Jane Smith)
11:00 AM   - Backup created
11:00 AM   - Updated JSON saved
11:00 AM - Publication update starts
11:01 AM   - Processing faculty 1/48...
11:15 AM   - Processing faculty 48/48
11:15 AM   - Summary: 12 new publications added
11:15 AM - COMPLETED SUCCESSFULLY
```

### Scheduled Run (2 Weeks Later)

```
2:00 AM - Task scheduler triggers
2:00 AM - Faculty sync: No changes (0/0/0)
2:01 AM - Publication update: Checking last 60 days
2:15 AM - Added 8 new publications
2:15 AM - Logs saved
2:15 AM - Task completed
```

---

## ğŸ› ï¸ Maintenance

### Regular Checks

**Monthly:**
- Review logs for errors
- Verify database is growing
- Check disk space

**Quarterly:**
- Test faculty sync manually
- Verify website selectors still work
- Update selectors if website changed

**Annually:**
- Review and clean old log files
- Verify ChromaDB performance
- Consider upgrading embedding model

### Monitoring

**Check logs folder:**
```
ls -la | findstr automated_update
```

**Latest run:**
```
type automated_update_YYYYMMDD_HHMMSS.log | findstr "SUMMARY"
```

**Scheduled task status:**
```
schtasks /Query /TN FacultyPulse_BiweeklyUpdate /FO LIST
```

---

## ğŸš¨ Troubleshooting

### Faculty Sync Issues

**No faculty found:**
- Website structure changed â†’ Update BeautifulSoup selectors
- Network issue â†’ Check connection
- Website blocking â†’ Add delay/headers

**Wrong faculty detected:**
- Name matching too loose â†’ Adjust matching logic
- Website has duplicate entries â†’ Add deduplication

### Publication Update Issues

**No new publications:**
- Normal if faculty haven't published recently
- Check OpenAlex API status
- Verify lookback period is reasonable

**Duplicates being added:**
- Check work_id extraction
- Verify existing_work_ids loading
- Run manual check script

### Scheduling Issues

**Task not running:**
- Check task is enabled
- Verify computer was on at scheduled time
- Check user permissions
- Review Task Scheduler event logs

**Task runs but fails:**
- Check log files for actual error
- Test manual run: `python automated_data_updater.py`
- Verify Python path in task

---

## ğŸ“š Documentation

- **[QUICKSTART_AUTOMATION.md](QUICKSTART_AUTOMATION.md)** - 5-minute setup guide
- **[AUTOMATED_UPDATES_README.md](AUTOMATED_UPDATES_README.md)** - Complete reference
- **[AUTOMATION_OVERVIEW.md](AUTOMATION_OVERVIEW.md)** - This file

### Code Documentation

Each script has inline documentation:
- `sync_faculty_data.py` - Faculty sync implementation
- `auto_update_publications.py` - Publication update implementation
- `automated_data_updater.py` - Main orchestrator
- `schedule_updates.py` - Scheduling setup

---

## ğŸ“ Best Practices

1. **Test before scheduling**
   - Always run manually first
   - Verify outputs are correct
   - Check logs for errors

2. **Monitor regularly**
   - Review logs monthly
   - Check for consistent patterns
   - Watch for unusual errors

3. **Keep backups**
   - Automated backups are created
   - Consider additional backups
   - Keep old logs for reference

4. **Update selectors**
   - If website changes, update immediately
   - Test after updates
   - Document changes

5. **Adjust frequency**
   - Start with bi-weekly
   - Adjust based on actual needs
   - More frequent = more API calls

---

## ğŸ“Š Performance

### Resource Usage

- **CPU:** Low (~5% during run)
- **Memory:** ~100-200 MB
- **Network:** Moderate (OpenAlex API calls)
- **Disk:** ~1-5 MB logs per run

### Timing

- **Faculty sync:** 10-30 seconds
- **Publication update:** 5-15 minutes
- **Total:** ~15-20 minutes

### Database Growth

- **Per faculty:** ~50-100 publications (lifetime)
- **Per publication:** ~50 KB
- **Total DB size:** ~100-200 MB for 50 faculty

---

## âœ… Success Criteria

### Healthy System

- âœ… Scheduled task shows "Ready" status
- âœ… Last run result: 0x0 (success)
- âœ… Recent log files present
- âœ… Database size growing appropriately
- âœ… No errors in logs
- âœ… Streamlit app shows new publications

### Red Flags

- âŒ No log files being created
- âŒ Consistent errors in logs
- âŒ Database not growing
- âŒ Task shows "Disabled"
- âŒ Last run result: error code

---

## ğŸ‰ Summary

You now have a **fully automated data collection system** that:

âœ… Keeps faculty list synchronized
âœ… Fetches new publications automatically
âœ… Runs every 2 weeks unattended
âœ… Creates comprehensive logs
âœ… Prevents duplicates
âœ… Handles errors gracefully
âœ… Requires minimal maintenance

**Your Faculty Pulse database will stay current automatically!**

---

## ğŸ”— Quick Links

**Setup:**
- [Quick Start (5 min)](QUICKSTART_AUTOMATION.md)
- [Full Documentation](AUTOMATED_UPDATES_README.md)

**Management:**
```bash
# Run manually
python automated_data_updater.py

# Set up scheduling
python schedule_updates.py

# Check status
schtasks /Query /TN FacultyPulse_BiweeklyUpdate
```

**Troubleshooting:**
- Check logs in Faculty_Pulse folder
- Review Task Scheduler event logs
- Test manual runs first

---

**Questions or Issues?** Check the detailed documentation or run test scripts to diagnose problems.
